{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to answer five questions:\n",
    "- Q1 - What part of my music taste can be described and predicted?\n",
    "- Q2 - What are my favorite genres?\n",
    "- Q3 - What are my favorite decades/periods?\n",
    "- Q4 - What are some albums that I should've liked according to a well-trained model, but didn't?\n",
    "- Q5 - What are some albums liked by me that a well trained-model expected me to dislike?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All five questions require statistical modelling. Even though on the first glance Q2 and Q3 could be answered only using descriptive statistics, we'll later see how selection bias in the sample obscures causality. In order to reliably estimate impact of genres and decades on my ratings, I need to use many factors at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My ratings are what our models will try to predict. To help us out, we have other users' ratings, as well as some metadata, at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataframes from data folder\n",
    "my_ratings = pd.read_csv('my_ratings.csv').set_index('album').rename_axis('album').sort_index()\n",
    "user_ratings = pd.read_csv('user_ratings.csv').set_index('album').sort_index()\n",
    "metadata = pd.read_csv('metadata.csv').set_index('album').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings.head() # 5 example records from my_ratings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings.head() # 5 example records from user_ratings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head() # 5 example records from metadata table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object `my_ratings` stores the ratings I gave to various albums, EPs and singles. Each album has one rating attached to it and there is no temporal element in the data - we assume all ratings are up to date. My ratings can take value of any real number between 0 and 5.\n",
    "Other users' ratings are stored in the `user_ratings` object. These ratings' values are between 0.5 and 5.0, with 0.5 increments. `NaN` values mean that a particular user hasn't rated this album. We can expect that appropriate handling of `NaN` values will be very important as we develop the model. Let's see how sparse is the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_share = user_ratings.isnull().sum().sum() / np.prod(user_ratings.shape) # share of fields with missing values in the user_ratings table\n",
    "print(f\"{NaN_share:.1%} of the fields are NaNs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other users' ratings comprise mostly albums that I also have rated but there can be a few exceptions. Additionally, my ratings can contain albums that other users haven't rated, or otherwise albums we don't have data on.\n",
    "Let's ensure that we have the same albums in both datasets, by dropping some rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Before cleaning - my ratings: {my_ratings.shape[0]}, user ratings: {user_ratings.shape[0]}') # number of records before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_intersection = list(set(user_ratings.index).intersection(set(my_ratings.index))) # list of albums present in both datasets\n",
    "my_ratings = my_ratings.loc[albums_intersection] # filter my_ratings\n",
    "user_ratings = user_ratings.loc[albums_intersection] # filter user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'After cleaning - my ratings: {my_ratings.shape[0]}, user ratings: {user_ratings.shape[0]}') # number of records after cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check of available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vs_avg_rating = my_ratings.join(user_ratings.mean(axis=1).rename('avg_rating')) # real scores and average user ratings in a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_corr = np.corrcoef(my_vs_avg_rating.SCORE, my_vs_avg_rating.avg_rating)[0][1] # correlation coefficient between my ratings and user ratings\n",
    "print(f'Correlation between my ratings and average user ratings: {ratings_corr:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genres strings can contain multiple genres for the same album. Let's split them so they can be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_split = [(index, row.genres.split(', ')) for index, row in metadata.iterrows()] # genres series of strings transformed into series of lists of strings\n",
    "genres_df = pd.DataFrame(genres_split)\n",
    "genres_df.set_index(0, inplace = True)\n",
    "genres_df = genres_df[1].explode().rename('genre') # creating dataframe where one row = one genre tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most popular genres in my database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = genres_df.value_counts().head(20).plot(kind='bar', figsize = [12, 6]) # count of genre appearances, top 20\n",
    "plt.ylabel('count of albums with genre')\n",
    "ax.bar_label(ax.containers[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many genres are assigned per album?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = genres_df.reset_index()[0].value_counts().value_counts().sort_index().plot(kind='bar', figsize = [12, 6]) # count of genres per album\n",
    "plt.xlabel('number of genres per album');\n",
    "plt.ylabel('count of albums')\n",
    "ax.bar_label(ax.containers[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What decade were the albums in my database released in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(10*np.floor(metadata.year/10)).astype(int).value_counts().sort_index().plot(kind='bar', figsize = [12, 6]) # count of albums per decade\n",
    "plt.xlabel('release decade');\n",
    "plt.ylabel('count of albums');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of model training let's create binary variables which check the genres strings against a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list containing potentially useful words to check against, based on above lists \n",
    "words_to_check = ['Rock', 'Punk', 'Pop', 'Post', 'Noise', 'Experimental', 'Rap', 'Hop', 'Jazz', 'Metal', 'Ambient', 'Indie', 'Art', 'Hardcore', 'Folk', 'Garage', 'Psychedel', 'Songwriter', 'Alternative', 'Industrial', 'Wave', 'Progressive', 'Avant', 'Techno', 'Synth', 'Math', 'Electronic', 'Jangle', 'Drone', 'Hypnagogic', 'Chamber', 'Contemporary', 'Power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_a_word(word):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    __________\n",
    "    word : str\n",
    "        Word which we'll check the genre list against.\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "    check_for_word : function\n",
    "        Function which can be applied on multiple genre lists.\n",
    "    \"\"\"\n",
    "    def check_for_word(genre_list):\n",
    "        # Helper function, instance of check_for_a_word, but for a particular word.\n",
    "        return word in genre_list\n",
    "    return check_for_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words_to_check:\n",
    "    metadata['Is_'+word] = metadata.genres.apply(check_for_a_word(word)) * 1 # creates multiple new binary features in the metadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.concat([metadata, pd.get_dummies(10*np.floor(metadata.year/10), prefix = 'Is')], axis = 1) # creates multiple binary features related to release decade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv_regression(\n",
    "    data, my_ratings, model=Ridge(alpha=100), fill = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform leave one regression on the provided dataset.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    data : pd.DataFrame\n",
    "        Independent variables with which model will be trained.\n",
    "    my_ratings : pd.DataFrame\n",
    "        Dependent variable which model attempts to predict.\n",
    "    model : object\n",
    "        Model which can be fit on provided data.\n",
    "    fill : float\n",
    "        Value to replace NaNs with, for user ratings.\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "    result : pd.DataFrame\n",
    "        Predictions for each observation.\n",
    "    \"\"\"\n",
    "    data_f = data.fillna(fill)\n",
    "    i = 1\n",
    "    albums = []\n",
    "    predictions = []\n",
    "    for index, _ in my_ratings.iterrows():\n",
    "        i += 1\n",
    "        X = data_f.loc[my_ratings.index].drop(index)\n",
    "        y = my_ratings.drop(index)[\"SCORE\"]\n",
    "        model.fit(X, y)\n",
    "        row_df = data_f.loc[[index]]\n",
    "        pred = model.predict(row_df)\n",
    "        albums.append(index)\n",
    "        predictions.append(pred[0])\n",
    "        print(f\"Predicted rating for {index}: {pred[0]:.2f}\")\n",
    "    result = pd.DataFrame({\"album\": albums, \"prediction\": predictions}).sort_values(\n",
    "        \"prediction\", ascending=False\n",
    "    ).set_index('album')\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, my_ratings):\n",
    "    \"\"\"\n",
    "    Evaluates predictions of my ratings generated by a model.\n",
    "    Parameters\n",
    "    __________\n",
    "    predictions : pd.DataFrame\n",
    "        Predictions generated by a model.\n",
    "    my_ratings : pd.DataFrame\n",
    "        Dependent variable which the model tried to predict.\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "    r2 : float\n",
    "        Coefficient of determination.\n",
    "    rmse : float\n",
    "        Root mean squared error.\n",
    "    \"\"\"\n",
    "    df = pd.concat([predictions, my_ratings], axis = 1)\n",
    "    r2 = r2_score(df.SCORE, df.prediction)\n",
    "    rmse = mean_squared_error(df.SCORE, df.prediction, squared = False)\n",
    "    return r2, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_A = loocv_regression(user_ratings, my_ratings, verbose = False) # run leave-one-out regression\n",
    "print(evaluate(result_A, my_ratings)) # calculate prediction error\n",
    "score_pred_A = pd.concat([result_A, my_ratings], axis = 1) # real scores and predictions in one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'SCORE', y = 'prediction', data = score_pred_A, alpha=0.25) # visualization of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_B = loocv_regression(metadata.drop(columns=['genres', 'year']), my_ratings, verbose = False) # run leave-one-out regression\n",
    "print(evaluate(result_B, my_ratings)) # calculate prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_B.prediction.round(1).value_counts().sort_index().plot(kind='bar') # visualization of prediction spread "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([user_ratings, metadata.drop(columns = ['ID', 'genres', 'year']).loc[user_ratings.index]], axis = 1) # user_ratings and metadata joined into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_C = loocv_regression(full_data, my_ratings, verbose = False) # run leave-one-out regression\n",
    "print(evaluate(result_C, my_ratings)) # calculate prediction error\n",
    "score_pred_C = pd.concat([result_C, my_ratings], axis = 1) # real scores and predictions in one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'SCORE', y = 'prediction', data = score_pred_C, alpha=0.25) # visualization of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Question 1: What part of my music taste can be described and predicted?\n",
    "Model C had a final R-squared coefficient of 20.4%, and that's the part of variance which could be explained by the model. This value can probably be higher with additional features or different models, but we have to keep in mind that we probably won't be able to predict most of the variance, since the topic we're tackling is subjective opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to look at coefficients, we'll run the model on all available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha = 100) # initialization of new model\n",
    "model.fit(full_data.fillna(2), my_ratings.SCORE) # single fit for all albums, without cross-validation\n",
    "coefs = pd.DataFrame({'feature': full_data.columns, 'coef': model.coef_}) # dataframe with variable coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How were the coefficients distributed for user ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.loc[~coefs.feature.str.startswith('Is')].coef.hist() # only user-related coefficients\n",
    "plt.xlabel('coefficient');\n",
    "plt.ylabel('count of users');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do coefficients look like for genre variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.loc[coefs.feature.str.startswith('Is_')].loc[(~coefs.feature.str.contains('19')) & (~coefs.feature.str.contains('20'))].sort_values('coef').set_index(['feature']).coef.plot(kind='bar') # only genre-related coefficients\n",
    "plt.xlabel('genre');\n",
    "plt.ylabel('coefficient');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Question 2: What are my favorite genres?\n",
    "Phrases which increase predicted ratings are Punk (like Post-Punk or Hardcore Punk), Hop (like Hip Hop, Glitch Hop etc), Hypnagogic (like Hypnagogic Pop), and Indie (like Indie Rock or Indie Surf).\n",
    "Phrases for which score predictions are lower, are Industrial, Electronic, Math (like Math Rock), Pop and Jazz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do coefficients look like for decade variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.loc[coefs.feature.str.startswith('Is_')].loc[(coefs.feature.str.contains('19')) | (coefs.feature.str.contains('20'))].sort_values('feature').set_index(['feature']).coef.plot(kind='bar') # only decade-related coefficients\n",
    "plt.xlabel('decade');\n",
    "plt.ylabel('coefficient');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Question 3: What are my favorite decades/periods?\n",
    "Albums from 2010s and especially 2020s seem to be highly rated by me. On the other hand, albums from 1970s and 1990s especially, received lower ratings. This already takes into account other users' ratings, as well as genres, so it's not a simple comparison between scores per decade, but an attempt to measure how decade influences predicted score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally use last LOO CV predictions to see which albums were most over- and underrated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred_C['diff'] = score_pred_C.SCORE - score_pred_C.prediction # prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred_C.sort_values('diff').head() # negative prediction error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Question 3:  What are some albums that I should've liked according to a well-trained model, but didn't?\n",
    "List is provided above. Maybe I should listen to these albums again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred_C.sort_values('diff', ascending = False).head() # positive prediction error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Question 5: What are some albums liked by me that a well trained-model expected me to dislike?\n",
    "List is provided above. It could be a good idea to check why my model stumbles on those. Maybe there are some additional variables which can address this and improve performance of the model on these outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a simple model it's possible to explain 20% of the variance in my ratings. Some variables required feature engineering, while others were ready to use. Linear model used (ridge regression) probably didn't do as well as more complicated models would, but it offered interpretability of coefficients, which was very important to answer some of the questions in the analysis. [Link to Medium article describing results in depth](https://medium.com/@mariusz.sz/why-do-i-like-music-1ef8477b469f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "376278b5f4aed9bd2e366b51602b371e503661628b53bd38297d8d6b4b8188e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('rymbaza')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
